---
title: B3.1
subtitle: Statistik der Kernzerfälle
---
# Einleitung

# Theoretische Grundlagen

## Statistische Tests
### Hypothesentest
Ein Hypothesentest oder Statistischer Test dient dazu, durch eine Hypothese mittels statistischer Messungen zu prüfen.

Dazu verwendet man eine *Nullhypothese*[^1] $H_0$ und eine *Gegenhypothese* oder *Alternativhypothese* $H_1$, die sich unterscheiden. Ziel des Tests ist es, die Alternativhypothese $H_1$ zu belegen. Falls dies nicht gelingt, muss man die Nullhypothese $H_0$ als wahr annehmen. Diese wird nicht überprüft. $[2]$

Aufgrund der Zufälligkeit der Ereignisse kann es dabei zwei Arten von Fehlern geben. Ein $\alpha$-Fehler beschreibt das irrtümliche Ablehnen von $H_0$, während ein $\beta$-Fehler das fälschliche Annehmen von $H_0$ bezeichnet.

[^1]: *Hypothesis to be nullified* $[5]$

### Fehlerarten
Ein *Fehler erster Art* oder $\alpha$-Fehler beschreibt die fälschliche Ablehnung der Nullhypothese $H_0$ in einem Statistischen Test. Man nimmt z.B. an, dass ein Würfel gezinkt ist $(H_1)$, obwohl er in Wahrheit fair ist $(H_0)$. Hierbei ist die $H_0$ die Annahme eines fairen Würfels. Man spricht hier auch von einem *falsch-positiven* Ergebnis. $[3]$

Ein *Fehler zweiter Art* oder *$\beta$-Fehler* beschreibt umgekehrt die fälschliche Akzeptanz der Nullhypothese $H_0$. Beispielsweise geht man davon aus, dass ein Würfel fair ist $(H_0)$, obwohl er tatsächlich unfair ist $(H_1)$. Man spricht hier auch von einem *falsch-negativen* Ergebnis. $[3]$

Die statistische Signifikanz beschreibt die erlaubte Wahrscheinlichkeit, einen $\alpha$-Fehler zu begehen. $[4]$ In einem *Alternativtest* dagegen beschreibt die Signifikanz die Wahrscheinlichkeit, einen $\alpha$- oder einen $\beta$-Fehler zu machen. Bei einer Signifikanz $Y$ sind $\alpha$- und $\beta$-Fehler mit einer Wahrscheinlichkeit von je $\frac{Y}{2}$ erlaubt.

### Der $\chi^2$-Anpassungstest
Der $\chi^2$-Anpassungstest dient dazu, eine Verteilung von Zufallsvariablen $A$ mit einer theoretischen Verteilung zu vergleichen. Man kann mithilfe des Tests bewerten, ob die Zufallsvariablen der Verteilung entsprechen können. Hierbei werden sowohl Fehler 1. Art als auch Fehler 2. Art berücksichtigt.

Die Grundidee dahinter ist, einen Erwartungswert $\braket{A}$ und seine Varianz $\sigma_A^2$ bewerten zu können. Das Maß für die Abweichung von der Hypothese wird für einen Freiheitsgrad durch $\chi^2$ beschrieben, [^2] was durch die $\chi^2$-Verteilung beschrieben wird.

$$
\begin{eqnarray}
	\chi^2 &=& \sum_i x_i^2
\end{eqnarray}
$$

Mithilfe der $\chi^2$-Verteilung kann eine Signifikanz $Y$ festgelegt werden. Damit kann ein Intervall $[\chi^2_\mathrm{min}, \chi^2_\mathrm{max}]$ durch die Verteilungsfunktion $F(x, f)$ ermittelt werden. Liegt das ermittelte $\chi^2$ in diesem Interval, so kann $H_1$ als signifikant gültig angenommen werden.

$$
\begin{eqnarray}
	F(\chi^2_\mathrm{min}, f) &=& \frac{Y}{2} \\
	F(\chi^2_\mathrm{max}, f) &=& 1 - \frac{Y}{2}
\end{eqnarray}
$$

Oft wird die Signifikanz von $Y=5\,\%$ gefordert, wodurch das Gültigkeitsintervall durch folgende Gleichungen bestimmt wird.

$$
\begin{eqnarray}
	F(\chi^2_\mathrm{min}, f) &=& 0.025 \tag{eq:ChiMinFormula} \\
	F(\chi^2_\mathrm{max}, f) &=& 0.975 \tag{eq:ChiMaxFormula}
\end{eqnarray}
$$

### Die $\chi^2$-Verteilung
Sei $A$ standardnormalverteilt[^6], dann ist die $\chi_1^2$-Verteilung eine quadrierte Normalverteilung mit einem Freiheitsgrad. Daher ist der Erwartungswert $\braket{\chi_1^2}=1$. Gibt es mehrere Freiheitsgrade $f$, so müssen $f$ Erwartungswerte $\braket{\chi_i^2}$ addiert werden, um den gesamten Erwartungswert zu ermitteln. Dies wird durch die Wahrscheinlichkeitsdichte (PDF[^3]) $f(x, f)$ beschrieben,[^4] wobei die Gammafunktion $\Gamma(x)$ benötigt wird.

$$
\begin{eqnarray}
	f(x, 2f) &=&
		\begin{cases}
				\frac{x^{f-1}}{2^f}
					\frac{\exp[-\frac{x}{2}]}{\Gamma(f)}
					& : x\ge 0 \\
				0 & : x < 0
		\end{cases} \\
	\Gamma(x) &=& \int_0^\infty t^{x-1}\cdot \mathrm e^t \,\mathrm dt
\end{eqnarray}
$$

Die Verteilungsfunktion (CDF[^5]) $F(x, f)$ ist dabei komplex und hat den Erwartungswert $\braket{\chi_f^2}=f$ und die Varianz $\sigma_{\chi^2}=2f$.

$$
\begin{align}
    F(x, 2f) &=
        \int_0^x
            \frac{y^{f-1}}{2^f}
                \frac{\exp[-\frac{y}{2}]}{\Gamma(f)}
            \,\mathrm dy \\
    \braket{\chi_f^2} &=
        \int_0^\infty x\cdot f(x, f)
            \,\mathrm dx
        &&= f \\
    \sigma_{\chi^2} &=
        \int_0^\infty \left(x - \braket{\chi_f^2}\right)^2 \cdot f(x, f)
            \,\mathrm dx
         &&=2f
\end{align}
$$

[^2]: Man könnte auch den Betrag $|x_i|$ anstatt des Quadrates $x_i^2$ wählen. Dies wird nicht gemacht, weil damit schwieriger zu rechnen ist.
[^3]: *probability density function*
[^4]: Achtung: Hier wird zur besseren Lesbarkeit $f(x, 2f)$ angegeben, die Zahl der Freiheitsgrade wird in der Funktion halbiert.
[^5]: *cumulative distribution function*
[^6]: Diese Annahme ist bei ausreichend vielen Messung durch das Gesetz der großen Zahl gerechtfertigt.

## Versuchsidee
In diesem Versuch wird $\ce{^{137}Cs}$ als radioaktive Probe verwendet, das eine Halbwertszeit $t_\frac{1}{2}\approx 30\,\mathrm a$ hat.

Damit soll die folgende Hypothese getestet, die Präparatstärke sei konstant und habe den Wert $\bar n$. Hierbei ist $\bar n$ der Mittelwert von vielen Einzelmessungen $n_i$ über eine kurze Zeit von $\Delta t=20\,\mathrm s$, der durch Gleichung $(\mathrm{mittlereRate})$ bestimmt wird. All diese $N$ Messungen werden in einem Zeitraum von wenigen Stunden absolviert.

Da der Zeitraum der Messungen sehr kurz gegen die Halbwertszeit ist, kann man annehmen, dass die Stärke der Probe sich im Rahmen der Messungenauigkeit nicht verändert.

Damit können die Differenzen zum Mittelwert $(n_i-\bar n)$ ermittelt werden. Nach dem zentralen Grenzwertsatz sind die relativen Differenzen standardnormalverteilt. Dadurch kann die Abweichung $\chi^2$ wie folgt ermittelt werden.

$$
\begin{eqnarray}
	\bar n &=& \sum_{i=1}^N \frac{n_i}{N} \tag{mittlereRate} \\
	\chi^2 &=& \sum_{i=1}^N \frac{(n_i-\bar n)^2}{m} \tag{ChiSquared}
\end{eqnarray}
$$

Die Messung hat einen einzelnen Freiheitsgrad $f=1$, dadurch können die Intervallgrenzen für $\chi^2$ nach $(\mathrm{eq:ChiMinFormula})$$-(\mathrm{eq:ChiMaxFormula})$ bestimmt werden. $[6]$

$$
\begin{eqnarray}
	\chi^2_\mathrm{min} &=& 0.001 \tag{ChiMin} \\
	\chi^2_\mathrm{max} &=& 5.024 \tag{ChiMax}
\end{eqnarray}
$$

### Einfluss der Totzeit
Die Totzeit der Länge $\tau$ hat einen Einfluss auf die gemessenen Zählraten. Anstatt einer Zählrate von $\frac{n_i}{\Delta t}$ wird eine totzeitkorrigierte Anzahl $k_i$ gemessen. Dadurch kann ein korrigierter Mittelwert $M$ nach $(\mathrm{mittlereRate})$ bestimmt werden und man erhält eine korrigierte Abweichung $\chi^2_\mathrm{korr}$.

$$
\begin{eqnarray}
	k_i &=&
		\frac{
			n_i
		}{
			1 - \frac{m}{\Delta t}\tau
		} \tag{korrRate} \\
	M &=& \sum_{i=1}^N \frac{k_i}{N} \tag{korrAVG} \\
	\chi^2_\mathrm{korr} &=& \sum_{i=1}^N
		\frac{(k_i - M)^2}{M} \tag{ChiKorrDef}
\end{eqnarray}
$$

Durch Einsetzen der Gleichungen $(\mathrm{korrRate})$-$(\mathrm{korrAVG})$ sowie $(\mathrm{ChiSquared})$ kann man $(\mathrm{ChiKorrDef})$ vereinfachen und man erhält die folgende vereinfachte Relation. Hier sieht man, dass die korrigierte Abweichung $\chi^2_\mathrm{korr}$ kleiner als die nicht-korrigierte Abweichung $\chi^2$ ist, was kontraintuitiv wahrgenommen werden kann.

$$
\begin{eqnarray}
	\chi^2_\mathrm{korr} &=&
		\frac{1}{1 - \frac{m}{\Delta t}\tau} \cdot \chi^2
\end{eqnarray}
$$

# Durchführung

# Auswertung

# Fazit

# Literatur
1. Universität zu Köln, "B3.1: Statistik der Kernzerfälle", Januar 2021, Online verfügbar unter [https://www.ikp.uni-koeln.de/fileadmin/data/praktikum/B3.1_statistik_de.pdf](https://www.ikp.uni-koeln.de/fileadmin/data/praktikum/B3.1_statistik_de.pdf)
2. Wikipedia, "Statistischer Test", [https://de.wikipedia.org/wiki/Statistischer_Test](https://de.wikipedia.org/wiki/Statistischer_Test), Abruf am 18.04.2024
3. Wikipedia, "Fehler 1. und 2. Art", [https://de.wikipedia.org/wiki/Fehler_1._und_2._Art](https://de.wikipedia.org/wiki/Fehler_1._und_2._Art), Abruf am 18.04.2024
4. Wikipedia, "Statistische Signifikanz", [https://de.wikipedia.org/wiki/Statistische_Signifikanz](https://de.wikipedia.org/wiki/Statistische_Signifikanz), Abruf am 18.04.2024
5. G. Gigerenzer, "Mindless statistics", 2004, *The Journal of Socio-Economics*, p.587-606, DOI [0.1016/j.socec.2004.09.033](https://doi.org/10.1016/j.socec.2004.09.033)
6. K. C. Kapur & M. Pecht, "Reliability Engineering": Appendix E, Wiley 2014, DOI [10.1002/9781118841716](https://doi.org/10.1002/9781118841716)
