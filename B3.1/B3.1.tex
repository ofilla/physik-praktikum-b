% based on a template made by the university of cologne
% http://www.mi.uni-koeln.de/wp-MIEDV/wp-content/uploads/2016/07/LaTeX-Vorlage.zip - 2023-11-02
\documentclass[12pt,a4paper]{scrartcl}

\addtokomafont{sectioning}{\rmfamily}
\usepackage[ngerman]{babel}% deutsches Sprachpaket wird geladen
\usepackage[T1]{fontenc} % westeuropäische Codierung wird verlangt
\usepackage[utf8]{inputenc}% Umlaute werden erlaubt
\usepackage[usenames]{color} % Erlaubt die Benutzung der namen im Farbpaket und deren Änderung
\usepackage{amsmath} % Erweiterung für den Mathe-Satz
\usepackage{amssymb} % alle Zeichen aus msam und msmb werden dargestellt
\usepackage{graphicx} % Graphiken und Bilder können eingebunden werden
%\usepackage{multirow} % erlaubt in einer Spalte einer Tabelle die Felder in mehreren Zeilen zusammenzufassen
\usepackage{enumerate} % erlaubt Nummerierungen
\usepackage{xurl} % Dient zur Auszeichnung von URLs; setzt die Adresse in Schreibmaschinenschrift.
\usepackage[center]{caption}  % Bildunterschrift wird zentriert
%\usepackage{subfigure} % mehrere Bilder können in einer fugure-Umgebung verwendet werden
%\usepackage{longtable} % Diese Umgebung ist ähnlich definiert wie die tabular-Umgebung, erlaubt jedoch mehrseitige Tabellen.
%\usepackage{paralist} % Modifikation der bereits bestehenden Listenumgebungen
\usepackage{lmodern}% Für die Schrift
\usepackage[hidelinks]{hyperref} % Links und Verweise werden innerhalb von PDF Dokumenten erzeugt
%\usepackage{wrapfig} % Das Paket ermöglicht es von Schrift umflossene Bilder und Tabellen einzufügen.
\usepackage{latexsym} % LaTeX-Symbole werden geladen
\usepackage{tikz} % Erlaubt es mit tikz zu zeichnen
\usepackage{tabularx} % Erlaubt Tabellen
\usepackage{algorithm} % Erlaubt Pseudocode
\usepackage{color} % Farbpaket wird geladen
%\usepackage{stmaryrd} % St Mary Road Symbole werden geladen
\usepackage{physics}
\usepackage{mhchem} % Chemie: \ce & \pu

\numberwithin{equation}{section} % Nummerierungen der Gleichungen, die durch equation erstellt werden, sind gebunden an die section
\newcommand{\HRule}{\rule{\linewidth}{0.7mm}}
\newcommand{\pu}[1]{\ensuremath{\mathrm{#1}}}
\newcommand{\code}[1]{\textsf{#1}}

\include{../media/Silbentrennung.tex}

% disable commands
\renewcommand{\[}{} % math block start
\renewcommand{\]}{\noindent} % math block end
\newcommand{\tightlist}{} % created in enumerations

\hypersetup{
  pdftitle={B3.1},
  pdfcreator={LaTeX via pandoc}}

\setcounter{secnumdepth}{6}
\setcounter{tocdepth}{6}

\begin{document}
\begin{titlepage}
	\pagestyle{empty}

	\begin{center}

	\textsc{\LARGE Universität zu Köln }\\ [0.4cm]
	\textsc{Mathematisch-Naturwissenschaftliche Fakultät} \\[1.5cm]

	\includegraphics[width=0.45\textwidth]{../media/uni.jpg}\\[1.5cm]  % Uni-Logo wird geladen

	\textsc{\Large Praktikum~B}\\[2mm]
	\textsc{}\\[10mm]
	\HRule \\[0.4cm]

		{	\Huge \bfseries B3.1}\\[0.4cm]
			{	\huge \bfseries Statistik der Kernzerfälle}\\[0.3cm]
	
	\HRule \\[3cm]

 	\begin{center}
		\textsc{\Large Catherine~Tran } \\[3pt]
		\textsc{\Large Carlo~Kleefisch } \\[3pt]
		\textsc{\Large Oliver~Filla } \\[3pt]
	\end{center}
	\end{center}
\end{titlepage}

\newpage
\tableofcontents
\newpage

\hypertarget{einleitung}{%
\section{Einleitung}\label{einleitung}}

In diesem Versuch wird die statistische Methode des \(\chi^2\)--Anpassungstests mithilfe von radioaktiver Strahlung untersucht. Dazu wird \(\ce{^{137}Cs}\) verwendet, dessen Stahlung mit einem Geiger--Müller--Zählrohr detektiert wird.

Basierend auf den Messergebnissen werden drei Hypothesen über die Präperatsstärke bewertet. Zudem soll die Totzeit des Detektores milhilfe der Zwei--Präperate--Methode bestimmt werden.

\clearpage
\hypertarget{theoretische-grundlagen}{%
\section{Theoretische Grundlagen}\label{theoretische-grundlagen}}
\hypertarget{Radioaktiver Zerfall}{\subsection{Radioaktiver Zerfall}\label{Radioaktiver Zerfall}}
Bei radioaktivem Zerfall wandelt sich ein Atomkern in einen anderen Atomkern um, indem Teilchen ausgestoßen werden.

Es wird zwischen $(\alpha)$--, $\beta$--und $\gamma$--Zerfall unterschieden. Der Energiegewinn durch den Zerfall wird durch den $Q$--Wert beschrieben und kann durch die Weizsäcker Massenformel ermittelt werden.

\hypertarget{Halbwertszeit}{\subsubsection{Halbwertszeit}\label{Halbwertszeit}}
Die Halbwertszeit $T_{1/2}$ ist die Zeit, in der die Hälfte einer Anzahl von Kernen oder Elementarteilchen eines Stoffes zerfällt. Sie ist eine charakteristische Größe für radioaktive Zerfälle , die unabhängig von der aktuell vorhandenen Substanzmenge ist. \cite{Halbwertszeit}

\hypertarget{Zerfallswahrscheinlichkeit}{\subsubsection{Zerfallswahrscheinlichkeit}\label{Zerfallswahrscheinlichkeit}}
Die \emph{Zerfallswahrscheinlichkeit} $\alpha$ ist eine isotopspezifische Konstante, die angibt wie schnell ein Kern des entsprechenden Isotops zerfällt. Sie steht in Relation mit der Halbwertrsbreite $T_{1/2}$. Dies wird im Folgenden  Abschnitt \ref{Herleitung Zerfallswahrscheinlichkeit} hergeleitet.

\begin{eqnarray}
	\alpha &=& \frac{\ln{(2)}}{T_{1/2}} \label{eq:Zerfallswahrscheinlichkeit}
\end{eqnarray}

\noindent
Das in diesem Versuch verwendete $\ce{^{137}Cs}$ hat eine Halbwertszeit von $T_{1/2}\approx30.08\mathrm{\,a}$ \cite{Chart of Nuclides}, was etwa $9.49 \cdot 10^8 \mathrm{\,s}$ entspricht. Daraus kann die Zerfallswahrscheinlichkeit $\alpha$ nach \eqref{eq:Zerfallswahrscheinlichkeit} bestimmt werden.

\begin{eqnarray}
	\alpha_\mathrm{Cs} &\approx& 7.3 \cdot 10^{-10} \mathrm{\,s^{-1}}
\end{eqnarray}

\hypertarget{Herleitung Zerfallswahrscheinlichkeit}{\subsubsection{Herleitung der Zerfallswahrscheinlichkeit}\label{Herleitung Zerfallswahrscheinlichkeit}}
Ein instabiler Kern mit einer Halbwertszeit $T_{1/2}$ zerfällt mit einer Wahrscheinlichkeit $\omega$ innerhalb einer Zeitspanne $\Delta t$. Falls diese Zeitspanne $\Delta t$ klein gegen $T_{1/2}$ ist, lässt $\omega$ linear annähern. Die Gegenwahrscheinlichkeit $(1-\omega)$ beschreibt demnach den Fall, dass der Kern nicht zerfällt.

\begin{eqnarray}
	\omega &=& \alpha \Delta t \label{eq:Zerfallswkt linear} \\
	1 - \omega &=& 1 - \alpha \Delta t
\end{eqnarray}

\noindent
Nun sollen größere Zeitspannen $t$ betrachtet werden. Dazu wird $t$ so in $k$ gleich große Teilzeitspannen unterteilt, dass jede Teilzeitspanne $t_i$ klein genug ist, um linear angenähert zu werden. Dann kann die Wahrscheinlichkeit $(1 - \omega_i)$ dafür ermittelt werden, dass in der Teilzeitspanne $t_i$ kein Zerfall stattfindet \eqref{eq:t_i kein zerfall}.

Daraus kann die Wahrscheinlichkeit $(1 - \omega)$ für den Erhalt des Kerns nach der Zeit $t$ ermittelt werden \eqref{eq:t kein zerfall}.

\begin{eqnarray}
	1 - \omega_i &=& \left(1 - \alpha \frac{t}{k}\right) \label{eq:t_i kein zerfall} \\
	1 - \omega &=& \left(1 - \alpha \frac{t}{k} \right)^k \label{eq:t kein zerfall}
\end{eqnarray}

\noindent
Um ein exaktes Ergebnis zu erzielen, müssen die Teilzeitabschnitte infinitesimal klein sein. Damit wird $k$ unendlich groß. Dadurch kann die Wahrscheinlichkeit $(1-\omega)$ für den Erhalt des Kerns durch eine Exponentialfunktion beschrieben werden.

Ensprechend kann die Wahrscheinlichkeit $\omega$ für einen Zerfall innerhalb der Zeitspanne $t$ beschrieben werden.

\begin{eqnarray}
	1 - \omega &=& \lim_{k \rightarrow \infty} \left(1 - \alpha \frac{t}{k} \right)^k \\
		&=& e^{- \alpha t} \\
	\omega &=& 1 - e^{-\alpha t}
\end{eqnarray}

\noindent
Die Zerfallswahrscheinlichkeit $\alpha$ lässt sich nun aus der Halbwertszeit.

\begin{eqnarray}
	\omega(T_{1/2}) &=& \frac{1}{2} \\
	\Rightarrow\alpha &=& \frac{\ln{(2)}}{T_{1/2}}
\end{eqnarray}

\hypertarget{statistik}{\subsection{Statistik}\label{statistik}}

\subsubsection{Zufallsvariablen}
\label{Zufallsvariablen}
Eine \emph{Zufallsvariable} ist eine Funktion $X$, die jedem Ereignis $\omega$ eines Zufallsexperiments eindeutig eine reelle Zahl zuordnet. Sie kann sowohl diskret als auch kontinuierlich sein.

\begin{eqnarray}
	X : \omega \rightarrow x(\omega) \in \mathbb{R}
\end{eqnarray}

\noindent
Das Ereignis $\omega$ des Zufallsexperiments kann direkt eine Zahl sein, wie beispielsweise die Augenzahl eines Würfelswurfs. Alternativ kann Jedem Ereignis des Zufallsexperiments wird eine Zahl zugeordnet werden, beispielsweise können bei einem Münzwurf dem Ereignis $\mathrm{Kopf}$ der Wert $0$ und dem Ereignis $\mathrm{Zahl}$ eine $1$ zugeordnet werden.

\subsubsection{Wahrscheinlichkeitsdichte}
\label{Wahrscheinlichkeitsdichte}
Eine \textit{Wahrscheinlichkeitsdichte} (PDF\footnote{\emph{Probability Density Function}}) ist eine Funktion $f(y)$, welche die Wahrscheinlichkeit $\mathbb P$ angibt, dass eine Zufallsvariable $X$ einen Wert innerhalb eines Intervalls $[a,b]$ annimmt.

\begin{eqnarray}
	\int_{a}^{b} f(y) dy &=& \mathbb P(X(\omega) \in [a,b])
	\label{eq:wahrscheinlichkeitsdichte}
\end{eqnarray}

\noindent
Die Wahrscheinlichkeitsdichte kann auch Werte über $1$ annehmen. Beispielsweise kann der Ort eines Punktteilchens durch eine $\delta$-Funktion beschrieben werden. Im Fall von diskreten Zufallsvariablen kann auch die Wahrscheinlichkeitsdichte diskret sein.

\subsubsection{Wahrscheinlichkeitsverteilung}
\label{Wahrscheinlichkeitsverteilung}
Eine \emph{Wahrscheinlichkeitsverteilungsfunktion} (CDF\footnote{\emph{Cumulative Distribution Function}, kumulative Verteilungsfunktion}) einer Zufallsvariable $X$ ist dagegen eine Funktion $F(y)$, die angibt mit welcher Wahrscheinlichkeit $\mathbb P$ die Zufallsvariable $X$ einen Wert kleiner gleich $y$ annimmt. Sie ist die integrierte Wahrscheinlichkeitsdichte $f(\omega)$.

\begin{eqnarray}
	F(y) &=& \mathbb P(X(\omega) \leq y) \\
	F(y) &=& \int_{- \infty}^{y} f(\tilde{y}) d\tilde{y}
\end{eqnarray}

\subsection{Wahrscheinlichkeitsverteilungen}
\label{Wahrscheinlichkeitsverteilungen}

\subsubsection{Binomialverteilung}
\label{Binomialverteilung}
Die \emph{Binomialverteilung} ist eine wichtige diskrete Wahrscheinlichkeitsverteilung. Sie beschreibt ein Zufallsexperiment, das genau zwei sich gegenseitig ausschließende Ereignisse $A$ und $B$ haben kann. Die entsprechenden Wahrscheinlichkeiten $\mathbb P$ können wie folgt definiert werden.

\begin{eqnarray}
	\mathbb P(A) &=& p \\
	\mathbb P(B) &=& 1 - p
\end{eqnarray}

\noindent
Dieses Experiment wird $N$-mal durchgeführt, wobei die einzelnen Ergebnisse jeder Wiederholung unabhängig von den Ergebnissen der vorherigen Wiederholungen sind. Die Zufallsvariable $X$ gibt dann die Anzahl $n$ an eingetretenen Ereignissen $A$ an. Dabei spielt die Reihenfolge, in der die Ereignisse $A$ eintreten, keine Rolle.

Die entsprechende  Wahrscheinlichkeit $P(N,n,p)$ gibt demnach die Wahrscheinlichkeit an, dass das Ereignis $A$ genau $n$-mal eintritt. Weiterhin können der Erwartungswert $\mu$ und die Varianz $\sigma^2$ bestimmt werden.

\begin{eqnarray}
	P(N,n,p) &=& \binom{N}{n} p^n (1-p)^{N-n} \\
	m &=& Np \\
	\sigma^2 &=& N p (1-p)
\end{eqnarray}

\noindent
Der Binomialkoeffizient $\binom{N}{n}$ dient dabei dazu, alle möglichen Reihenfolgen zu berücksichtigen, in der das Ereignis $A$ eintreten kann, wobei der restliche Term die Wahrscheinlichkeit angibt, dass das Ereignis $A$ in einer bestimmten Reihenfolge $n$-mal eintritt.

\subsubsection{Poissonverteilung}
\label{Poissonverteilung}
Die \emph{Poissonverteilung} beschreibt Reihen von Zufallsvariablen, die unabhängig voneinander eintreten. Sie ist eine weitere diskrete Verteilung mit der Wahrscheinlichkeitsdichte $P(n,\lambda)$, Erwartungswert $m$ und Varianz $\sigma^2$.

\begin{eqnarray}
	P_\lambda(n) &=& \frac{\lambda^n}{n!} e^{-\lambda}
	\label{eq:poisson} \\
	m &=& \lambda\\
	\sigma^2 &=& \lambda \\
	\Rightarrow\quad \frac{\sigma}{m} &=&\frac{1}{\sqrt{m}} \label{eq:Poisson STD/EW}
\end{eqnarray}

\noindent
Die Poissonverteilung $P_\lambda(n)$ folgt als Grenzfall aus der Binomialverteilung $P(N, n, p)$ mit infinitesimal kleinen Schrittgrößen $(p\rightarrow 0)$ und unendlich vielen Schritten $(N\rightarrow 0)$. Dabei bildet $\lambda\equiv Np$ eine Konstante. Die Poissonverteilung ist als Näherung für die Binomialverteilung zu verwenden, falls folgende Bedingung erfüllt ist.

\begin{eqnarray}
	P(n, \lambda)  &=& \lim_{N \rightarrow \infty \atop p\rightarrow 0} P(N, n, p) \\
	N p &\leq& 10
\end{eqnarray}

\subsubsection{Gaußverteilung}
\label{Gaußverteilung}
Die \emph{Gaußverteilung} ist eine kontinuierliche Verteilung. Ihre Wahrscheinlichkeitsdichte $P(x,\mu,\sigma)$ wird folgendermaßen mithilfe des Erwartungswerts $\mu$ und der Varianz $\sigma^2$ beschrieben. Die \emph{Normalverteilung}  ist eine Gaußverteilung mit $\mu=\sigma^2=1$.

\begin{eqnarray}
	P(x,\mu,\sigma) &=& \frac{1}{\sqrt{2 \pi\sigma^2}} \exp\left[- \frac{1}{2} \left(\frac{x - \mu}{\sigma}\right)^2\right]
\end{eqnarray}

\noindent
Der Grenzwert der Poissonverteilung für $\lambda \rightarrow \infty$ liefert die Gaußverteilung.

\begin{eqnarray}
	\lim_{\lambda \rightarrow \infty} \frac{\lambda^n e^{-\lambda}}{n!} = \frac{1}{\sqrt{2 \pi \lambda}} e^{- \frac{(x-\lambda)^2}{2\lambda}}
\end{eqnarray}

\noindent
Weiterhin konvergiert die Binomialverteilung nach dem \emph{Satz von Moivre--Laplace} für $N \rightarrow \infty$ mit der Bedingung $0 < p < 1$ gegen die Normalverteilung. Eine Faustregel besagt, dass die Normalverteilung schon eine gute Näherung für die Binomialverteilung liefert, sobald gilt die untenstehende Bedingung erfüllt ist.

\begin{eqnarray}
	\lim_{N \rightarrow \infty} \binom{N}{n} p^n (1-p)^{N-n}
		&=& \frac{1}{\sqrt{2 \pi N p (1-p)}} e^{- \frac{(x - Np)^2}{2 N p (1-p)}} \\
	Np (1-p) &\geq& 9
\end{eqnarray}

\hypertarget{Intervallverteilung}{\subsection{Intervallverteilung}\label{Intervallverteilung}}
Die \emph{Intervallverteilung} ist dann gefragt, wenn nicht die Anzahl an eingetroffenen Ereignissen $A$, sondern stattdessen die Zeit zwischen zwei oder mehr Ereignissen $A$ interessant ist.

Für Kernzerfälle ist ihre Wahrscheinlichkeitsdichte $P_n$ wie folgt gegeben. Sie ähnelt der Poissonverteilung, hat aber einen zusätzlichen Faktor $a$.

\begin{eqnarray}
	P_n &=& a \frac{(at)^n}{n!} e^{-at}
\end{eqnarray}

\noindent
Damit gibt die kumulative Verteilungsfunktion $\int_{t_0}^{t_1} P_n \,\mathrm dt \label{eq:P_n_int}$ die Wahrscheinlichkeit an, dass in dem Zeitintervall $[t_0,t_1]$ zwei Ereignisse im Abstand $t$ stattgefunden haben, sowie $n$ weitere Ereignisse zwischen diesen beiden. Somit haben in der Zeit $t$ exakt $n+2$ Ereignisse stattgefunden.

Somit gibt die Verteilungsfunktion für $n=0$ die Wahrscheinlichkeit an, dass die Zeit $t$ zwischen zwei aufeinanderfolgenden Zerfällen innerhalb des Intervalls $[t_0, t_1]$ liegt.

\hypertarget{Herleitung Intervallverteilung}{\subsection{Herleitung}\label{Herleitung Intervallverteilung}}
Nun soll die Wahrscheinlichkeitsdichte $P_n$ der Intervallverteilung hergeleitet werden.

Hierzu wird die Wahrscheinlichkeit $W$ bestimmt, dass die Zeit zwischen zwei Zerfällen, zwischen denen genau $n$ andere Zerfälle stattfinden, den Wert $\Delta t$ annimmt. $W$ setzt sich aus dem Produkt zweier Einzelwahrscheinlichkeiten $W_1$ und $W_2$ zusammen.

$W_1$ gibt die Wahrscheinlichkeit an, dass im Zeitintervall $\Delta t$ genau $n$ weitere Zerfälle stattfinden. Dies wird durch eine Poissonverteilung \eqref{eq:poisson} beschrieben, deren Erwartungswert $\lambda = a\Delta t$ beträgt und durch die Zerfallswahrscheinlichkeit $a$ beschrieben wird.

$W_2$ hingegen gibt die Wahrscheinlichkeit an, dass nach der Zeit $\Delta t$ in einer sehr kurzen Zeit $\mathrm dt$ ein Zerfall stattfindet. Aufgrund der kurzen Zeitspanne kann dies linear genähert werden, wie es bei der Herleitung der Zerfallswahrscheinlichkeit in Abschnitt \ref{Herleitung Zerfallswahrscheinlichkeit}  in Gleichung \eqref{eq:Zerfallswkt linear} gemacht wurde.

\begin{eqnarray}
	W_1 &=& \frac{(a\Delta t)^n}{n!} \mathrm{e}^{-a\Delta t} \\
	W_2 &=& a \,\mathrm dt \\
	W &=& W_1 \cdot W_2 \\
		&=& \frac{\left(a\Delta t\right)^n}{n!}  \mathrm{e}^{-a\Delta t} \cdot a \,\mathrm dt
\end{eqnarray}

\noindent
Da die Wahrscheinlichkeit $W$ das Integral der Wahrscheinlichkeitsdichte $P_n$ darstellt, wird $P_n$ durch differenzieren ermittelt.

\begin{eqnarray}
	P_n &=& \frac{\mathrm dW}{\mathrm dt} \\
		&=& a \frac{\left(at\right)^n}{n!} e^{-at}
\end{eqnarray}

\hypertarget{statistische-tests}{%
\subsection{Statistische Tests}\label{statistische-tests}}

\hypertarget{hypothesentest}{%
\subsubsection{Hypothesentest}\label{hypothesentest}}

Ein Hypothesentest oder Statistischer Test dient dazu, durch eine Hypothese mittels statistischer Messungen zu bewerten.

Dazu verwendet man eine \emph{Nullhypothese}\footnote{\emph{Hypothesis  to be nullified} \([5]\)} \(H_0\) und eine \emph{Gegenhypothese} oder \emph{Alternativhypothese} \(H_1\), die sich unterscheiden. Ziel des Tests ist es, die Alternativhypothese \(H_1\) zu belegen. Falls dies nicht gelingt, muss man die Nullhypothese \(H_0\) als wahr annehmen. Diese wird nicht überprüft. \([2]\)

Aufgrund der Zufälligkeit der Ereignisse kann es dabei zwei Arten von Fehlern geben. Ein \(\alpha\)--Fehler beschreibt das irrtümliche Ablehnen von \(H_0\), während ein \(\beta\)--Fehler das fälschliche Annehmen von \(H_0\) bezeichnet.

\hypertarget{fehlerarten}{%
\subsubsection{Fehlerarten}\label{fehlerarten}}
Ein \emph{Fehler erster Art} oder \(\alpha\)--Fehler beschreibt die fälschliche Ablehnung der Nullhypothese \(H_0\) in einem Statistischen Test. Man nimmt z.B. an, dass ein Würfel gezinkt ist \((H_1)\), obwohl er in Wahrheit fair ist \((H_0)\). Hierbei ist die \(H_0\) die Annahme eines fairen Würfels. Man spricht hier auch von einem \emph{falsch--positiven} Ergebnis. \([3]\)

Ein \emph{Fehler zweiter Art} oder \emph{\(\beta\)--Fehler} beschreibt umgekehrt die fälschliche Akzeptanz der Nullhypothese \(H_0\). Beispielsweise geht man davon aus, dass ein Würfel fair ist \((H_0)\), obwohl er tatsächlich unfair ist \((H_1)\). Man spricht hier auch von einem \emph{falsch--negativen} Ergebnis. \([3]\)

Die statistische Signifikanz beschreibt die erlaubte Wahrscheinlichkeit, einen \(\alpha\)--Fehler zu begehen. \([4]\) In einem \emph{Alternativtest} dagegen beschreibt die Signifikanz die Wahrscheinlichkeit, einen \(\alpha\)- oder einen \(\beta\)--Fehler zu
machen. Bei einer Signifikanz \(Y\) sind \(\alpha\)-- und \(\beta\)--Fehler mit einer Wahrscheinlichkeit von je \(\frac{Y}{2}\) erlaubt.

\hypertarget{der-chi2anpassungstest}{%
\subsubsection{\texorpdfstring{Der
\(\chi^2\)--Anpassungstest}{Der \textbackslash chi\^{}2--Anpassungstest}}\label{der-chi2anpassungstest}}

Der \(\chi^2\)--Anpassungstest dient dazu, eine Verteilung von Zufallsvariablen \(A\) mit einer theoretischen Verteilung zu vergleichen. Man kann mithilfe des Tests bewerten, ob die Zufallsvariablen der Verteilung entsprechen können. Hierbei werden sowohl Fehler 1. Art als auch Fehler 2. Art berücksichtigt.

Die Grundidee dahinter ist, einen Erwartungswert \(\expval{A}\) und seine Varianz \(\sigma_A^2\) bewerten zu können. Das Maß für die Abweichung von der Hypothese wird für einen Freiheitsgrad durch \(\chi^2\) beschrieben,\footnote{Man könnte auch den Betrag \(|x_i|\)   anstatt des Quadrates \(x_i^2\) wählen. Dies wird nicht gemacht, weil   damit schwieriger zu rechnen ist.} was durch die \(\chi^2\)--Verteilung beschrieben wird.

\begin{eqnarray}
    \chi^2 &=& \sum_i x_i^2
\end{eqnarray}

Mithilfe der \(\chi^2\)--Verteilung kann eine Signifikanz \(Y\) festgelegt werden. Damit kann ein Intervall \([\chi^2_\mathrm{min}, \chi^2_\mathrm{max}]\) durch die Verteilungsfunktion \(F(x, f)\) ermittelt werden. Liegt das ermittelte \(\chi^2\) in diesem Interval, so kann \(H_1\) als signifikant gültig angenommen werden.

\begin{eqnarray}
    F(\chi^2_\mathrm{min}, f) &=& 1 - \frac{Y}{2} \\
    F(\chi^2_\mathrm{max}, f) &=& \frac{Y}{2}
\end{eqnarray}

Oft wird die Signifikanz von \(Y=5\,\%\) gefordert, wodurch das Gültigkeitsintervall durch folgende Gleichungen bestimmt wird.

\begin{eqnarray}
    F(\chi^2_\mathrm{min}, f) &=& 0.975 \label{eq:ChiMinFormula} \\
    F(\chi^2_\mathrm{max}, f) &=& 0.025 \label{eq:ChiMaxFormula}
\end{eqnarray}

Falls \(\chi^2<\chi^2_\mathrm{min}\) das Ergebnis des Tests ist, sind die Daten zu gut an die These angepasst. Dies kann beispielsweise durch Overfitting entstehen.

\hypertarget{pearsons-chi2test}{%
\paragraph{\texorpdfstring{Pearsons
\(\chi^2\)--Test}{Pearsons \textbackslash chi\^{}2--Test}}\label{pearsons-chi2test}}

Eine Variante des \(\chi^2\)--Tests betrachtet nur ein Ende der Gauß--Verteilung. Hierbei wird die Signifikanz \(Y\) verwendet, um ein maximal gültiges \(\chi_\mathrm{max}^2\) zu bestimmen, dabei wird auf einen minimalen Wert verzichtet. \cite{McHugh} Damit kann eine Hypothese nur dann abgelehnt werden, wenn \(\chi^2\) zu groß ist, ein zu kleines \(\chi^2\) ist dabei nicht betrachtet. Auch hier wird oft eine Signifikanz von \(5\,\%\) verwendet.

\begin{eqnarray}
    F(\chi^2_\mathrm{max}, f) &=& Y \\
    F(\chi^2_\mathrm{max}, f) &=& 0.05 \label{eq:ChiMaxPearson} \\
\end{eqnarray}

\hypertarget{die-chi2verteilung}{%
\subsubsection{\texorpdfstring{Die
\(\chi^2\)--Verteilung}{Die \textbackslash chi\^{}2--Verteilung}}\label{die-chi2verteilung}}

Sei \(A\) standardnormalverteilt\footnote{Diese Annahme ist bei ausreichend vielen Messung durch das Gesetz der großen Zahl gerechtfertigt.}, dann ist die \(\chi_1^2\)--Verteilung eine quadrierte Normalverteilung mit einem Freiheitsgrad. Daher ist der Erwartungswert \(\expval{\chi_1^2}=1\). Gibt es mehrere Freiheitsgrade \(f\), so müssen \(f\) Erwartungswerte \(\expval{\chi_i^2}\) addiert werden, um den gesamten Erwartungswert zu ermitteln. Dies wird durch die Wahrscheinlichkeitsdichte (PDF\footnote{\emph{probability density function}}) \(f(x, f)\) beschrieben,\footnote{Achtung: Hier wird zur besseren Lesbarkeit \(f(x, 2f)\) angegeben, die Zahl der Freiheitsgrade wird in der Funktion halbiert.} wobei die Gammafunktion \(\Gamma(x)\) benötigt wird.

\begin{eqnarray}
    f(x, 2f) &=&
        \begin{cases}
                \frac{x^{f-1}}{2^f}
                    \frac{\exp[-\frac{x}{2}]}{\Gamma(f)}
                    & : x\ge 0 \\
                0 & : x < 0
        \end{cases} \\
    \Gamma(x) &=& \int_0^\infty t^{x-1}\cdot \mathrm e^t \,\mathrm dt
\end{eqnarray}

Die Verteilungsfunktion (CDF\footnote{\emph{cumulative distribution function}}) \(F(x, f)\) ist dabei komplex und hat den Erwartungswert \(\expval{\chi_f^2}=f\) und die Varianz \(\sigma_{\chi^2}=2f\).

\begin{align}
    F(x, 2f) &=
        \int_0^x
            \frac{y^{f-1}}{2^f}
                \frac{\exp[-\frac{y}{2}]}{\Gamma(f)}
            \,\mathrm dy \\
    \expval{\chi_f^2} &=
        \int_0^\infty x\cdot f(x, f)
            \,\mathrm dx
        &&= f \\
    \sigma_{\chi^2} &=
        \int_0^\infty \left(x - \expval{\chi_f^2}\right)^2 \cdot f(x, f)
            \,\mathrm dx
         &&=2f
\end{align}

\hypertarget{versuchsidee}{%
\subsection{Versuchsidee}\label{versuchsidee}}

In diesem Versuch wird \(\ce{^{137}Cs}\) als radioaktive Probe verwendet, das eine Halbwertszeit \(t_\frac{1}{2}\approx 30\,\mathrm a\) hat.

Damit soll die folgende Hypothese getestet, die Präparatstärke sei konstant und habe den Wert \(\bar n\). Hierbei ist \(\bar n\) der Mittelwert von vielen Einzelmessungen \(n_i\) über eine kurze Zeit von \(\Delta t=20\,\mathrm s\), der durch Gleichung \(\eqref{mittlereRate}\) bestimmt wird. All diese \(N\) Messungen werden in einem Zeitraum von wenigen Stunden absolviert.

Da der Zeitraum der Messungen sehr kurz gegen die Halbwertszeit ist, kann man annehmen, dass die Stärke der Probe sich im Rahmen der Messungenauigkeit nicht verändert.

Damit können die Differenzen zum Mittelwert \((n_i-\bar n)\) ermittelt werden. Nach dem zentralen Grenzwertsatz sind die relativen Differenzen standardnormalverteilt. Dadurch kann die Abweichung \(\chi^2\) wie folgt ermittelt werden.

\begin{eqnarray}
    \bar n &=& \sum_{i=1}^N \frac{n_i}{N} \label{mittlereRate} \\
    \chi^2 &=& \sum_{i=1}^N \frac{(n_i-\bar n)^2}{\bar n} \label{ChiSquared}
\end{eqnarray}

\subsubsection{Das Geiger--Müller--Zählrohr}
\label{Geiger--Müller--Zählrohr}
Ein Geiger--Müller--Zählrohr besteht aus einem edelgasgefüllten Zylinderkondensator mit einem dünnem Anodendraht in der Mitte. Das elektrische Potential ist somit ein zylindersymmetrisch, um die Anode herum ist es am stärksten. Dies ist in Abbildung \ref{fig:Geiger--Müller--Zählrohr} schematisch dargestellt.

Wenn ein Photon in den Zylinder eintritt und auf ein Gasteilchen trifft, wird die Energie des Photons übertragen und ein Elektron aus dem Atom gelöst. Durch das elektrische Potential wird das freie Elektron zur Anode hin beschleunigt und stößt auf dem Weg mit weiteren Gasteilchen. Dadurch sammeln sich immer mehr Elektronen um den Anodendraht.

Währenddessen regen sich die Gasteilchen durch Photonenemission ab und erzeugen die sogenannte Geiger--Entladung. Hierbei ionisieren die entstandene Photonen weitere Gasteilchen, somit entstehen weitere Elektronen. Da die Photonen überall innerhalb des Zählrohr sein können, findet die Entladung in dem gesamten Zählrohr statt.

Die Zeit, während der die relativ langsame Wolke aus ionisierten Gasteilchen nach außen zur Zylinderwand wandert, wird \emph{Totzeit} genannt. In diesem Zeitraum existiert um den Anodendraht kein Potential. Daher es können dann keine Elektronen beschleunigt werden, obwohl weitere Strahlungsquanten ins Zählrohr hinein dringen können. In dieser Zeit kann keine Strahlungen gemessen werden.

Um eine Mehrfachentladung von Gasteilchen während der Totzeit an der Zylinderwand zu vermeiden wird ein starker Widerstand mit ca. $10^8\,\Omega$ zwischen Hochspannungsversorgung und Anode geschaltet. Dadurch ist die Hochspannung nach einer Entladung nicht ausreichend für eine weitere Entladung.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{../media/B3.1/640px-Geiger_Mueller_Counter_with_Circuit-de.svg.png}
	\caption{Aufbau eines typischen Geiger--Müller--Zählrohrs \cite{File:Geigerzählrohr}}
	\label{fig:Geiger--Müller--Zählrohr}
\end{figure}

\subsubsection{Totzeit}
\label{Totzeit}
Ganz allgemein beschreibt Totzeit $\tau$ die Zeit, die nach der Registrierung eines Ereignisses durch einen Detektor verstreicht, bis der Detektor wieder messbereit ist. \cite{Totzeit}

Wie schon beschrieben ist während der Totzeit $\tau$ keine Strahlungsmessung möglich. Dadurch weicht die gemessene Zählrate $a^\prime$ von der tatsächlichen Rate $a$ ab. Um die tatsächliche Rate zu bestimmen, muss für jedes gemessene Teilchen die Anzahl der Detektionen in der Totzeit $a\tau$ addiert werden. Dies beschreibt die tatsächlich geschehenen Ereignisse, die während der Totzeit nicht gemessen werden können.

Analog kann der gemessene Mittelwert $m^\prime$ von in einem Zeitraum $T$ gemessenen Ereignissen korrigiert werden, um den korrigierten Mittelwert $m=aT$ zu erhalten.

\begin{eqnarray}
	a &=& a^\prime \cdot(1 + a\tau) \\
	\Leftrightarrow\quad a &=& \frac{a^\prime}{1-a^\prime\tau} \label{eq:Totzeitkorrigiert Rate}\\
	m &=&\frac{m'}{1-a'\tau} \label{eq:Totzeitkorrigiert EW}
\end{eqnarray}

\noindent
Das Verhältnis von Varianz $\sigma^2$ und Mittelwert $m$ der gemessenen Verteilung entspricht der tatsächlichen Verteilung. Weisen die Messwerte eine Poissonverteilung auf, so kann man folgende Relationen ermitteln.

\begin{eqnarray}
	\frac{\sigma}{m}&=&\frac{\sigma^\prime}{m^\prime}\\
	\Rightarrow\quad \sigma^{\prime\,2} & = &\frac{m^{\prime\,2}}{m} \\
		&=& m^\prime\cdot\frac{a^\prime}{a} \\
		&=& m^\prime\cdot(1-a^\prime\tau) %\\
	%\sigma^2 &=& \sigma^{\prime\,2}\left(\frac{a}{a^\prime}\right)^2\\
	%	&=& \frac{m^\prime}{1-a\tau}
\end{eqnarray}

\noindent
Hierbei wurden die Verhältnisse $\frac{\sigma}{m}$ und $\frac{a^\prime}{a}$ durch die Gleichungen \eqref{eq:Poisson STD/EW} und \eqref{eq:Totzeitkorrigiert EW} beschrieben.

\hypertarget{einfluss-der-totzeit}{%
\subsubsection{Einfluss der Totzeit}\label{einfluss-der-totzeit}}

Die Totzeit der Länge \(\tau\) hat einen Einfluss auf die gemessenen Zählraten. Anstatt einer Zählrate von \(\frac{n_i}{\Delta t}\) wird eine totzeitkorrigierte Anzahl \(k_i\) gemessen. Dadurch kann ein korrigierter Mittelwert \(M\) nach \(\eqref{mittlereRate}\) bestimmt werden und man erhält eine korrigierte Abweichung \(\chi^2_\mathrm{korr}\). Die korrigierte Rate wird nach Gleichung \eqref{eq:Totzeitkorrigiert Rate} bestimmt.

\begin{eqnarray}
    k_i &=&
        \frac{
            n_i
        }{
            1 - \frac{m}{\Delta t}\tau
        } \label{korrRate} \\
    M &=& \sum_{i=1}^N \frac{k_i}{N} \label{korrAVG} \\
    \chi^2_\mathrm{korr} &=& \sum_{i=1}^N
        \frac{(k_i - M)^2}{M} \label{ChiKorrDef}
\end{eqnarray}

\noindent
Durch Einsetzen der Gleichungen \(\eqref{korrRate}\)-\(\eqref{korrAVG}\) sowie \(\eqref{ChiSquared}\) kann man \(\eqref{ChiKorrDef}\) vereinfachen und man erhält die folgende vereinfachte Relation. Hier sieht man, dass die korrigierte Abweichung \(\chi^2_\mathrm{korr}\) kleiner als die nicht--korrigierte Abweichung \(\chi^2\) ist, was kontraintuitiv wahrgenommen werden kann.

\begin{eqnarray}
    \chi^2_\mathrm{korr} &=&
        \frac{1}{1 - \frac{m}{\Delta t}\tau} \cdot \chi^2
\end{eqnarray}

\subsubsection{Zwei--Präparate--Methode}
Die Zwei--Präparate--Methode wird verwendet, um die Totzeit zu messen. Man misst die Zählrate von zwei verschiedenen Präparaten $z^\prime_{1/2}$ jeweils einzeln und dann von beiden zusammen $z^\prime_{12}$. Zusätzlich wird die Untergrundzählrate $z^\prime_0$ ohne Präparate gemessen.

Somit erhält man gemessene Werte $z^\prime_i$ und sowie wahre Werte $z_i$. Die wahren Zählraten $z_i$ sind durch die Präparate und den Untergrund entstanden.

Nun seien $p_{1,\,2,\,12}$ die Zählraten, die sich durch die Verwendung von Präparaten ergeben. Daraus erhält man ein lösbares Gleichungssystem mit von je acht Gleichungen und Unbekannten.  Die letzten Gleichungen ergeben sich durch die Totzeitkorrektur \eqref{eq:Totzeitkorrigiert Rate} der Zählraten.

%\begin{eqnarray}
%	z_1 &=& p_1+u \\
%	z_2 &=& p_2+u \\
%	z_{12} &=& p_{12}+u \\
%	z_1 &=& \frac{z^\prime_1}{1-z^\prime_1 \tau} \\
%	z_2 &=& \frac{z^\prime_2}{1-z^\prime_2 \tau} \\
%	z_{12} &=& \frac{z^\prime_{12}}{1-z^\prime_{12} \tau} \\
%	u &=&\frac{u^\prime}{1-u^\prime\tau} \\
%	p_{12} &=& p_1+p_2
%\end{eqnarray}
\begin{eqnarray}
	p_{12} &=& p_1 + p_2 \\
	\forall i\in\{1,\,2,\,12\}:\qquad
		z_i &=& p_i + z_0 \\
	\forall i\in\{0,\,1,\,2,\,12\}:\quad
		z_i &=& \frac{z^\prime_i}{1-z^\prime_i \tau}
\end{eqnarray}

\noindent
Die Lösung dieses Gleichungssystems ergibt die Totzeit.

\begin{eqnarray}
	\tau _{1,\,2} &=& \frac{-B \pm \sqrt{B^2 - 4AC}}{2A} \\
	A &=& u'z'_{12}z'_2 - z'_1z'_12z'_2 + u'z'_{12}z'_1 - u'z'_1z'_2 \nonumber\\
	B &=& -2z'_{12}u' + 2z'_1z'_2 \nonumber\\
	C &=& z^\prime _{12} - z^\prime _1 + u^\prime  - z^\prime _2 \nonumber
\end{eqnarray}

\clearpage
\hypertarget{durchfuxfchrung}{%
\section{Durchführung}\label{durchfuxfchrung}}
\subsection{Versuchsaufbau}
Der Aufbau beinhaltet zwei $\ce{^{137}Cs}$--Quellen und Zählrohr mit angeschlossener Elektronik. Die am Zählrohr angeschlossene Spannung lässt sich variieren, die Zählrohrelektronik erzeugt ein Rechtecksignal je detektiertem Ereignis. Dieses Signal wird an einen Zähler und an einen Computer übertragen. Auf dem Computer können die Ereignisse zeitaufgelöst gemessen werden.

Zur Bearbeitung der Daten sind am Computer drei Python-Programme vorinstalliert, mit denen die Messdaten verarbeitet werden können. Mit \code{divide.py} Ereignisse in Zeitintervallen fester Größe, z.B.  jeweils $10\mathrm{\,s}$, gezählt. Mittels \code{binomial.py} kann eine Binomialverteilung aus den Daten extrahiert werden, mit \code{interval.py} eine Intervallverteilung.

\subsection{Messungen}
Es wurden $3$ lange und $12$ kurze Messungen durchgeführt.

Bei den ersten beiden langen Messungen wurde nur Probe $A$ verwendet, bei der dritten langen Messung die Probe $A$ und $B$. Eine Einzelmessung von Probe $A$ und die gemeinsame Messung wurden bei einer Spannung von $500\mathrm{\,V}$ durchgeführt, die zweite Einzelmessung bei $600\mathrm{\,V}$. Hierbei wurden die Ereignisse zeitaufgelöst gemessen.

Die $12$ kurzen Messung dienten der Bestimmung der Totzeit mit der Zwei--Präparate--Methode. Hierzu wurden jeweils bei Spannungen von $500\mathrm{\,V}$, $550\mathrm{\,V}$ und $600\mathrm{\,V}$ die Ereignisse in jeweils $5\mathrm{\,min}$ gemessen. Dabei wurden die Proben $A$ und $B$ sowohl einzeln als auch gemeinsam verwendet. Die letzten drei kurzen Messungen erfolgten ohne Proben, um den Untergrund zu vermessen.

\clearpage
\hypertarget{auswertung}{%
\section{Auswertung}\label{auswertung}}

\hypertarget{poissonverteilung}{%
\subsection{Poissonverteilung}\label{poissonverteilung}}

\hypertarget{gauuxdfverteilung}{%
\subsection{Gaußverteilung}\label{gauuxdfverteilung}}

\hypertarget{intervallverteilung}{%
\subsection{Intervallverteilung}\label{intervallverteilung}}

\hypertarget{chi2test}{%
\subsection{\texorpdfstring{\(\chi^2\)--Test}{\textbackslash chi\^{}2--Test}}\label{chi2test}}

Es werden \(51\) zufällige Messergebnisse gewählt, aus denen \(\chi^2\)
gewählt wird. Da der Mittelwert einen statistischen Freiheitsgrad
bindet, bleiben \(50\) Freiheitsgrade übrig, um die
Gültigkeitsintervalle zu bilden.

\[
\begin{eqnarray}
    \chi^2_\mathrm{min} &=& 32.357 \\
    \chi^2_\mathrm{max} &=& 71.420
\end{eqnarray}
\]

\hypertarget{hypothese-h_1}{%
\subsubsection{\texorpdfstring{Hypothese
\(H_1\)}{Hypothese H\_1}}\label{hypothese-h_1}}

Nach \(\eqref{ChiSquared}\):

\[
\begin{eqnarray}
    \bar x &=& \bar n \\
    \chi^2_1 &=& \sum_i \frac{(x_i-\bar x)^2}{\bar x}
\end{eqnarray}
\]

\hypertarget{hypothese-h_2}{%
\subsubsection{\texorpdfstring{Hypothese
\(H_2\)}{Hypothese H\_2}}\label{hypothese-h_2}}

\[
\begin{eqnarray}
    \bar x^\prime &=& 0.9\cdot\bar n \\
    \chi^2_2 &=& \sum_i \frac{(x_i-\bar x^\prime)^2}{\bar x^\prime}
\end{eqnarray}
\]

\hypertarget{hypothese-h_3}{%
\subsubsection{\texorpdfstring{Hypothese
\(H_3\)}{Hypothese H\_3}}\label{hypothese-h_3}}

Mit \(i\in[0, N]\):

\[
\begin{eqnarray}
    \expval{x(i)} &=& \bar n - i \\
    \chi^2_3 &=& \sum_i \frac{(x_i-(n - i))^2}{(n - i)}
\end{eqnarray}
\]

\hypertarget{totzeit}{%
\subsubsection{Halbwertszeit}\label{totzeit}}
\begin{eqnarray}
	N(t) &=& \bar{n} \cdot \exp[-\lambda t] \\
	\bar{n}-1 &=& \bar{n} \cdot \exp[-\lambda \Delta t] \\
	\Rightarrow \lambda &=& \frac{1}{\Delta t} \ln(\frac{\bar{n}}{\bar{n}-1}) \\
	\Rightarrow T_{1/2} &=& \frac{\Delta t \ln(2)}{\ln(\frac{\bar{n}}{\bar{n}-1})}
\end{eqnarray}

\clearpage
\hypertarget{fazit}{%
\section{Fazit}\label{fazit}}

\clearpage
\hypertarget{literatur}{\section{Literaturverzeichnis}\label{literatur}}
\renewcommand{\section}[2]{}

\begin{thebibliography}{99}
\bibitem{uni}
	Universität zu Köln, ``B3.1: Statistik der Kernzerfälle'', Januar
	2021, Online verfügbar unter
	\url{https://www.ikp.uni-koeln.de/fileadmin/data/praktikum/B3.1_statistik_de.pdf}
\bibitem{Wiki:Statistischer Test}
	Wikipedia, ``Statistischer Test'',
	\url{https://de.wikipedia.org/wiki/Statistischer_Test}, Abruf am
	18.04.2024
\bibitem{Fehler 1. und 2. Art}
	Wikipedia, ``Fehler 1. und 2. Art'',
	\url{https://de.wikipedia.org/wiki/Fehler_1._und_2._Art}, Abruf am
	18.04.2024
\bibitem{Statistische Signifikanz}
	Wikipedia, ``Statistische Signifikanz'',
	\url{https://de.wikipedia.org/wiki/Statistische_Signifikanz}, Abruf am
	18.04.2024
\bibitem{Gigerenzer}
	G. Gigerenzer, ``Mindless statistics'', 2004, \emph{The Journal of
	Socio--Economics}, p.587-606, DOI
	\href{https://doi.org/10.1016/j.socec.2004.09.033}{0.1016/j.socec.2004.09.033}
\bibitem{Kapur}
	K. C. Kapur \& M. Pecht, ``Reliability Engineering'': Appendix E,
	Wiley 2014, DOI
	\href{https://doi.org/10.1002/9781118841716}{10.1002/9781118841716}
\bibitem{Cramer}
	E. Cramer \& U. Kamps, ``Grundlagen der Wahrscheinlichkeitsrechnung
	und Statistik'', Springer 2020, DOI~\href{https://doi.org/10.1007/978-3-662-60552-3}{10.1007/978-3-662-60552-3}
\bibitem{Puhani}
	J. Puhani, ``Statistik'', Springer 2020, DOI~\href{https://doi.org/10.1007/978-3-658-28955-3}{10.1007/978-3-658-28955-3}
\bibitem{McHugh}
	Mary L. McHugh, ``The Chi-square test of independence'', Biochemia Medica, DOI~\href{https://doi.org/10.11613/BM.2013.018}{10.11613/BM.2013.018}
\bibitem{Halbwertszeit}
	Lexikon der Physik, ``Halbwertszeit'', \url{https://www.spektrum.de/lexikon/physik/halbwertszeit/6327}, Abruf am 07.06.2024
\bibitem{Chart of Nuclides}
	National Nuclear Data Center, ``Chart of Nuclides'',
	\url{https://www.nndc.bnl.gov/nudat3}, $\ce{^{137}Cs}$,
	Abruf am 07.05.2024
\bibitem{File:Geigerzählrohr}
	Wikimedia, ``File:Geiger Mueller Counter with Circuit-de.svg'', \url{https://commons.wikimedia.org/wiki/File:Geiger_Mueller_Counter_with_Circuit-de.svg}, Abruf am 22.04.2024
\bibitem{ulfkonrad}
	Ulf Konrad, ``Geiger--Müller--Zählrohr'', \url{https://www.ulfkonrad.de/physik/geiger-mueller-zaehlrohr}, Abruf am 22.04.2024
\bibitem{Totzeit}
	Lexikon der Physik, ``Totzeit'', \url{https://www.spektrum.de/lexikon/physik/totzeit/14643}, Abruf am 22.04.2024
\end{thebibliography}
\end{document}
